ETL Orquestrado com Apache Airflow e Docker: Governan√ßa e Qualidade de Dados

Este reposit√≥rio cont√©m o c√≥digo e a arquitetura para um pipeline robusto de Extract, Transform, Load (ETL), focado na orquestra√ß√£o de Data Warehouse (DW) utilizando Apache Airflow, conteinerizado com Docker, e com uma etapa rigorosa de Data Quality (DQ) para garantir a integridade dos dados anal√≠ticos.

üöÄ Tecnologias

Categoria

Tecnologia

Uso

Orquestra√ß√£o

Apache Airflow

Agendamento e monitoramento dos fluxos de ETL (DAGs).

Conteineriza√ß√£o

Docker/Docker Compose

Isolamento e reprodutibilidade do ambiente (Airflow, PostgreSQL).

Banco de Dados

PostgreSQL

Servidor do Data Warehouse (DW) e simula√ß√£o do sistema de origem (OLTP/Stage).

Modelagem

Star Schema

Modelo dimensional otimizado para consultas anal√≠ticas.

üìê Arquitetura do Projeto

A solu√ß√£o √© composta por uma arquitetura multi-container que simula um ambiente de produ√ß√£o de dados completo:

Airflow Containers: Inclui o Scheduler, Worker e Webserver, gerenciando a execu√ß√£o das DAGs.

PostgreSQL DW: O banco de dados de destino onde o Star Schema √© constru√≠do e os dados s√£o carregados.

PostgreSQL Stage: Simula o banco de dados de origem (OLTP), de onde o Airflow extrai os dados brutos.

O Modelo Dimensional

O DW √© modelado em Star Schema, garantindo performance anal√≠tica:

Tabela Fato (FactOrder): Cont√©m as m√©tricas de neg√≥cio (ex: SalesAmount) e as chaves substitutas (SKs).

Tabelas Dimens√£o (DimCustomer, DimProduct, DimDate): Fornecem o contexto para as an√°lises.

‚úÖ Data Quality (DQ) como Gate de Governan√ßa

O principal diferencial deste pipeline √© a implementa√ß√£o de um gate de Data Quality (DQ) ap√≥s o carregamento da Tabela Fato.

A tarefa de DQ executa comandos SQL para verificar:

Integridade Referencial: Contagem de chaves substitutas (SK) nulas na FactOrder.

Validade de Dom√≠nio: Verifica√ß√£o de valores il√≥gicos em m√©tricas cr√≠ticas (ex: SalesAmount <= 0).

Mecanismo de Falha: Se a contagem de erros for maior que zero, o pipeline √© abortado imediatamente. Isso impede que dados inconsistentes cheguem √† camada de Business Intelligence (BI), assegurando a confiabilidade dos relat√≥rios.

‚öôÔ∏è Vis√£o Geral das DAGs

As DAGs (Directed Acyclic Graphs) s√£o respons√°veis por cada etapa do ETL.

DAG

Fun√ß√£o

Descri√ß√£o

dag_init_dw.py

Inicializa√ß√£o

Executa o DDL (Data Definition Language) para criar o Schema e todas as tabelas do Star Schema no PostgreSQL.

dag_load_dim_date.py

Carga de Dimens√£o √önica

Gera e popula a tabela DimDate com atributos temporais para um horizonte de tempo definido.

etl_data_warehouse_v2

Pipeline de Produ√ß√£o

A DAG principal. Executa o carregamento de dimens√µes em paralelo, carrega a FactOrder e, por √∫ltimo, executa a Data Quality Check (DQ).

üõ† Como Rodar o Projeto

Para replicar o ambiente localmente, voc√™ precisar√° ter o Docker e o Docker Compose instalados.

Clone o reposit√≥rio:

git clone (https://github.com/ramonkuster/etl_olap_airflow.git)
cd airflow-project


Inicie os Containers:
O docker-compose.yml ir√° subir o Airflow (Webserver, Scheduler, Worker), o PostgreSQL do DW e o PostgreSQL de Stage.

docker-compose up -d


Acesse o Airflow:
Aguarde alguns minutos para que todos os servi√ßos inicializem.

Interface Web: Acesse http://localhost:8080 (usu√°rio e senha padr√£o: airflow/airflow).

Execute as DAGs:

Execute primeiro a DAG de inicializa√ß√£o: dag_init_dw.py.

Em seguida, execute as DAGs de carga, come√ßando pela principal, etl_data_warehouse_v2, para observar o fluxo paralelo e a checagem de DQ.
